{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e540d48c-53ec-43ed-80ad-7b59e5647339",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c5f9cc-71e5-4eb1-8fe3-a0d1d1c32b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0661b702-9be2-40b3-a75a-819921d21c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.4.0 (from torchvision)\n",
      "  Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (70.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->torchvision)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0->torchvision)\n",
      "  Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n",
      "Using cached torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
      "Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/797.2 MB\u001b[0m \u001b[31m14.1 kB/s\u001b[0m eta \u001b[36m15:41:02\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/http/client.py\", line 479, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/socket.py\", line 707, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/leo/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e92f6b-595a-494f-adf6-0b1a21bb4340",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d5560b-4dc1-4468-a691-a63c214d8361",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download training data from open datasets.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mFashionMNIST(\n\u001b[1;32m      3\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     transform\u001b[38;5;241m=\u001b[39mToTensor(),\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Download test data from open datasets.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m test_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mFashionMNIST(\n\u001b[1;32m     11\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     transform\u001b[38;5;241m=\u001b[39mToTensor(),\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ec299-4e78-4afd-bd5c-ef782fae163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1fce78-1aa8-4942-b74a-9a00136dfe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Models\n",
    "'''\n",
    "    To define a neural network in PyTorch, we create a class that inherits from the `nn.Module`. We define the layers of the network in the __init__ function and specify how data will pass through\n",
    "    the network in the forward function. To accelerate operations in the neural network, we move it to the GPU of MPS if available.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96ce609-9633-4138-9d65-08a178a6ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6a5dc-1987-4c34-8dc5-5e13bd9ff63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f814899-c251-46a4-b8ed-6184d47680bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the Model Parameters\n",
    "## To train a model, we need a loss function and an optimizer.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parametes(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4eac3-3fc4-4074-8732-c03634d2fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model's parameters.\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        print(f\"loss: {loss:>7f} [{current:>5d} / {size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3488f-59d6-4f6f-9a20-a8a2404740c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also check the model's performance against the test dataset to ensure it is learning\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argumax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct) :> 0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55807c53-75fd-4325-9676-fb2767386025",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    The training process is conducted over several iterations (epochs). During each epoch, the model learns parameters to make better predictions. We print the model's accuracy and \n",
    "    loss at each epoch; we'd like to see the accuracy increase and the loss decrease with every epoch.\n",
    "'''\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epochs {t+1}\\n---------------------------------------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8550ae9-31d9-4baf-8c8f-baf313dd5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Models\n",
    "# A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved Pytorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8ab9a-4fce-4ab2-bfe3-916f3153214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Models\n",
    "# The process for loading a model includes re-creating the model structure and loading the state dictionary into it.\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900a034-590f-4209-a600-562e24b4724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcdea8-8c9d-476a-9de5-beebc2136f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d317c-4e8d-462c-928a-750abe0f1b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f6e4d-5d49-460d-ae2a-a81e8f131766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8ca92c-3cfc-4503-8a1f-5321689072f3",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb590d-224b-4bc7-9918-9f51bf5ca7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7783a-59a9-4d74-877d-a9e759a8c9d5",
   "metadata": {},
   "source": [
    "## Initializing a Tensor\n",
    "Tensors can be initialized in various ways. Take a look at the following examples:\n",
    "\n",
    "**Directly from data**  \n",
    "Tensors can be created directly from data. The data type is automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7f661-9cd3-4b18-b09a-f5a0c7aba7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308bf65-c9e4-4932-a3a1-e26e9e562db7",
   "metadata": {},
   "source": [
    "## From a NumPy array\n",
    "Tensors can be created from NumPy arrays (and vice versa -see Bridge with NumPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f2cc1-d62a-4513-a56e-9afb6d75933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa3c64-380f-4a2b-80ea-05ee23b58c7a",
   "metadata": {},
   "source": [
    "## From another tensor:\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f162be-2be5-44a0-8055-ecd44b57ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"One Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeedeea-6ffd-4204-9628-b16003612542",
   "metadata": {},
   "source": [
    "## With random or constant values:\n",
    "'shape' is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d96d3a-be00-47ab-9edf-a3faaa72a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aaff14-7276-4e6d-8025-4a5104525949",
   "metadata": {},
   "source": [
    "# Attributes of a Tensor\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b277bd-7991-421c-9560-6bc428111892",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of the tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490eb6c3-a555-4a31-ae4a-78406914aded",
   "metadata": {},
   "source": [
    "# Operations on Tensors  \n",
    "Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are described in the pytorch documentation.\n",
    "Each of these operations can be run on the GPU (at typically higher speeds than on a CPU).\n",
    "By default, tensors are created on the CPU. We need to explicitly move tensors to GPU using .to method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e56e5-46fd-4830-b10b-bccf580b623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865e7b1-7e65-42dc-acf5-ced65a39de9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd042fd-dcb7-4ce7-9727-4b8b9243483e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9a6ee-d39a-4dd4-a1e3-4098af6322cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4390a5f-a7bc-497c-8f5d-5fd54be227d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
